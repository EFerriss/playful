{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playful: Find your new favorite computer game\n",
    "I built [an app that recommends computer games on Steam](http://www.playful.live/).\n",
    "\n",
    "To do that, I obtained Steam data and performed some initial data exploration using\n",
    "* scrapy\n",
    "* API calls\n",
    "* PostgreSQL\n",
    "\n",
    "Next I generated, optimized, and validated a model using\n",
    "* matrix factorization\n",
    "* collaborative filtering with implicit feedback\n",
    "* sparse matrices\n",
    "* LightFM\n",
    "\n",
    "Finally I built a web app to turn that model into recommendations for anyone who owns games on Steam using:\n",
    "* item-to-item recommendations \n",
    "* pandas\n",
    "* flask\n",
    "* Amazon web services\n",
    "\n",
    "Here is a more detailed overview of what that process looked like.\n",
    "\n",
    "## Import stuff\n",
    "My config.py file is not on GitHub. You need your own Steam API key and database information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from app.config import api_key, db_username, db_password, db_host, db_port\n",
    "from urllib.request import Request, urlopen\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape reviews for user IDs\n",
    "Scraping hub has [a detailed example of how to scrape reviews from the Steam store using scrapy]((https://blog.scrapinghub.com/2017/07/07/scraping-the-steam-game-store-with-scrapy/), complete with code in a GitHub repo. \n",
    "\n",
    "I scraped all of the reviews, which took about 4 days, in case later on I want to incorporate some of that information into the recommendations. For now the only thing I'm using from that exercize is a list of ~400,000 unique Steam user IDs of the review writers. I did not include any other Steam users, so my recommendations are biased toward games owned by people who have written reviews. \n",
    "\n",
    "Due to space limitations on GitHub, I am sharing only a small part of 1 of the 3 scrapy output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1094 unique steam user IDs in the sample data.\n"
     ]
    }
   ],
   "source": [
    "def load_reviews():\n",
    "    reviews = []\n",
    "    path_to_scraped_data = 'example_data//'\n",
    "    files = ['scraped_reviews.jl']\n",
    "    \n",
    "    for file in files:\n",
    "        with open(''.join((path_to_scraped_data, file)), 'r') as f:\n",
    "            for line in f:\n",
    "                reviews.append(json.loads(line))\n",
    "                \n",
    "    return reviews\n",
    "\n",
    "scraped_reviews = load_reviews()\n",
    "\n",
    "user_ids = []\n",
    "for review in scraped_reviews:\n",
    "    try:\n",
    "        user_ids.append(review['user_id'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "unique_users = list(set(user_ids))\n",
    "print('There are', len(unique_users), 'unique steam user IDs in the sample data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API calls for game ownership\n",
    "This took about 5 minutes, and you have to be online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGamesOwned(player_id):\n",
    "    req = Request('http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=%s&steamid=%s&format=json&include_played_free_games=True&include_appinfo=True'%(api_key, player_id))\n",
    "    try:\n",
    "        data_raw = urlopen(req).read()\n",
    "        data_json = json.loads(data_raw)\n",
    "        return data_json['response']['games']\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def get_all_games_owned_by_players(user_ids):\n",
    "    users_and_their_games = {}\n",
    "    for idx, gamer_id in enumerate(user_ids):\n",
    "        users_and_their_games[gamer_id] = getGamesOwned(gamer_id)\n",
    "    return users_and_their_games\n",
    "\n",
    "users_and_their_games = get_all_games_owned_by_players(unique_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the ownership data into pandas and PostgreSQL\n",
    "Every user-game pair gets its own row in the database. For example, say I have data for only 2 unique Steam users, Katie and Minchun. If Katie owns 20 games and Minchun owns 3 games, I'll end up with 23 rows. \n",
    "\n",
    "You have to have a SQL server installed and running with apppropriate password information for this section to work. Also, I used Windows. The syntax will be different on a Mac or Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_column = []\n",
    "app_column = []\n",
    "\n",
    "for user in unique_users:\n",
    "    for game in users_and_their_games[user]:\n",
    "        user_column.append(user)\n",
    "        app_column.append(game['appid'])\n",
    "\n",
    "user_game_df = pd.DataFrame({'user_id':user_column, 'app_id':app_column})\n",
    "\n",
    "db_name  = 'playful'\n",
    "engine = create_engine('postgresql+psycopg2://%s:%s@%s:%s/%s'%(db_username,db_password,db_host,db_port,db_name))\n",
    "\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "    \n",
    "user_game_df.to_sql('user_games_table', engine, if_exists='replace')\n",
    "\n",
    "user_game_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL query for most popular games\n",
    "This is how I came up with the list of the 12 most popular games on the app homepage.\n",
    "\n",
    "At scale, this SQL query was much faster than a similar analysis in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\" SELECT app_id, COUNT(user_id) AS \"n_owners\"\n",
    "                FROM user_games_table\n",
    "                GROUP BY app_id\n",
    "                ORDER BY n_owners DESC\n",
    "                LIMIT 12\n",
    "            \"\"\"\n",
    "\n",
    "con = None\n",
    "con = psycopg2.connect(database=db_name, user=db_username, password=db_password, host=db_host, port=db_port)\n",
    "most_popular_game_ids = pd.read_sql_query(sql_query, con).app_id.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More details coming soon!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
