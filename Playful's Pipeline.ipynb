{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playful: Find your new favorite computer game\n",
    "Here is the basic outline of how I  built [an app that recommends computer games on Steam](http://www.playful.live/) using a combination of python and PostgreSQL.\n",
    "\n",
    "## Import stuff\n",
    "My config.py file is not on GitHub. You need your own Steam API key and database information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from app.config import api_key, db_username, db_password, db_host, db_port\n",
    "from urllib.request import Request, urlopen\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pickle\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape reviews for user IDs\n",
    "Scraping hub has [a detailed example of how to scrape reviews from the Steam store using scrapy]((https://blog.scrapinghub.com/2017/07/07/scraping-the-steam-game-store-with-scrapy/), complete with code in a GitHub repo. \n",
    "\n",
    "I scraped all of the reviews, which took about 4 days, in case later on I want to incorporate some of that information into the recommendations. For now the only thing I'm using from that exercize is a list of ~400,000 unique Steam user IDs of the review writers. I did not include any other Steam users, so my recommendations are biased toward games owned by people who have written reviews. \n",
    "\n",
    "Due to space limitations on GitHub, I am sharing only a small part of 1 of the 3 scrapy output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1094 unique steam user IDs in the sample data.\n"
     ]
    }
   ],
   "source": [
    "def load_reviews():\n",
    "    reviews = []\n",
    "    path_to_scraped_data = 'example_data//'\n",
    "    files = ['scraped_reviews.jl']\n",
    "    \n",
    "    for file in files:\n",
    "        with open(''.join((path_to_scraped_data, file)), 'r') as f:\n",
    "            for line in f:\n",
    "                reviews.append(json.loads(line))\n",
    "                \n",
    "    return reviews\n",
    "\n",
    "scraped_reviews = load_reviews()\n",
    "\n",
    "user_ids = []\n",
    "for review in scraped_reviews:\n",
    "    try:\n",
    "        user_ids.append(review['user_id'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "unique_users = list(set(user_ids))\n",
    "print('There are', len(unique_users), 'unique steam user IDs in the sample data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API calls for game ownership\n",
    "This took about 5 minutes, and you have to be online for the API call to work.\n",
    "\n",
    "In the real app, I'm using a pickled version of the results to avoid complications in case a user deletes their account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGamesOwned(player_id):\n",
    "    req = Request('http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=%s&steamid=%s&format=json&include_played_free_games=True&include_appinfo=True'%(api_key, player_id))\n",
    "    try:\n",
    "        data_raw = urlopen(req).read()\n",
    "        data_json = json.loads(data_raw)\n",
    "        return data_json['response']['games']\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def get_all_games_owned_by_players(user_ids):\n",
    "    users_and_their_games = {}\n",
    "    for idx, gamer_id in enumerate(user_ids):\n",
    "        users_and_their_games[gamer_id] = getGamesOwned(gamer_id)\n",
    "    return users_and_their_games\n",
    "\n",
    "users_and_their_games = get_all_games_owned_by_players(unique_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the ownership data into pandas and PostgreSQL\n",
    "Every user-game pair gets its own row in the database. For example, say I have data for only 2 unique Steam users, Katie and Minchun. If Katie owns 20 games and Minchun owns 3 games, I'll end up with 23 rows. \n",
    "\n",
    "You have to have a SQL server installed and running with apppropriate password information for this section to work. Also, I used Windows. The syntax will be different on a Mac or Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6420</td>\n",
       "      <td>76561198072350122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>76561198072350122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320</td>\n",
       "      <td>76561198072350122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340</td>\n",
       "      <td>76561198072350122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>76561198072350122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id            user_id\n",
       "0    6420  76561198072350122\n",
       "1     220  76561198072350122\n",
       "2     320  76561198072350122\n",
       "3     340  76561198072350122\n",
       "4     360  76561198072350122"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_column = []\n",
    "app_column = []\n",
    "\n",
    "for user in unique_users:\n",
    "    for game in users_and_their_games[user]:\n",
    "        user_column.append(user)\n",
    "        app_column.append(game['appid'])\n",
    "\n",
    "user_game_df = pd.DataFrame({'user_id':user_column, 'app_id':app_column})\n",
    "\n",
    "db_name  = 'playful'\n",
    "engine = create_engine('postgresql+psycopg2://%s:%s@%s:%s/%s'%(db_username,db_password,db_host,db_port,db_name))\n",
    "\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "    \n",
    "user_game_df.to_sql('user_games_table', engine, if_exists='replace')\n",
    "\n",
    "user_game_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL query for most popular games\n",
    "This is how I came up with the list of the 12 most popular games on the app homepage. I'll convert the game IDs into actual names shortly.\n",
    "\n",
    "At scale, this SQL query was much faster than a similar analysis in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the IDs of the most-owned games\n",
      "223530\n",
      "550\n",
      "72850\n",
      "218620\n",
      "730\n",
      "620\n",
      "230410\n",
      "205790\n",
      "304930\n",
      "4000\n",
      "49520\n",
      "238960\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\" SELECT app_id, COUNT(user_id) AS \"n_owners\"\n",
    "                FROM user_games_table\n",
    "                GROUP BY app_id\n",
    "                ORDER BY n_owners DESC\n",
    "                LIMIT 12\n",
    "            \"\"\"\n",
    "\n",
    "con = None\n",
    "con = psycopg2.connect(database=db_name, user=db_username, password=db_password, host=db_host, port=db_port)\n",
    "most_popular_game_ids = pd.read_sql_query(sql_query, con).app_id.values\n",
    "\n",
    "print('Here are the IDs of the most-owned games')\n",
    "for game in most_popular_game_ids:\n",
    "    print(game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine unique users and games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points 232255\n",
      "number of users: 914\n",
      "number of games: 19716\n",
      "Sparsity of data in the example interactions matrix: 1.289%\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\" SELECT *\n",
    "                FROM user_games_table\n",
    "            \"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sql_query, con)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "unique_users = df.user_id.unique()\n",
    "unique_games = df.app_id.unique()\n",
    "\n",
    "n_users = len(unique_users)\n",
    "n_games = len(unique_games)\n",
    "n_datapoints = len(df)\n",
    "sparsity = 100* n_datapoints / (n_users*n_games)\n",
    "\n",
    "print('number of data points', n_datapoints)\n",
    "print('number of users:', n_users)\n",
    "print('number of games:', n_games)\n",
    "print('Sparsity of data in the example interactions matrix: {:4.3f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappers\n",
    "Each game has 3 different ways we can refer to it:\n",
    "* the game's name (gamename)\n",
    "* the game's Steam ID (gameid)\n",
    "* the game's location in the interactions matrix (idx)\n",
    "\n",
    "I made 6 different mapper dictionaries to convert from one game representation of a game to another. The game name to Steam ID mapping is from the API, but here and in the app I'm using stored data for that data and 2 of the mapper dictionaries. \n",
    "\n",
    "The users also get mapped to indexes in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicker Heroes will be game number 2000 in the interactions matrix and has Steam game ID 363970\n",
      "\n",
      "The most-owned games in this sample of data by name instead of game ID:\n",
      "Left 4 Dead 2 Beta\n",
      "Left 4 Dead 2\n",
      "The Elder Scrolls V: Skyrim\n",
      "PAYDAY 2\n",
      "Counter-Strike: Global Offensive\n",
      "Portal 2\n",
      "Warframe\n",
      "Dota 2 Test\n",
      "Unturned\n",
      "Garry's Mod\n",
      "Borderlands 2\n",
      "Path of Exile\n"
     ]
    }
   ],
   "source": [
    "## Game name and game ID information from API\n",
    "# req = Request('http://api.steampowered.com/ISteamApps/GetAppList/v2/?key=%s'%(api_key))\n",
    "# data_raw = urlopen(req).read()\n",
    "# data_json = json.loads(data_raw)['applist']['apps']\n",
    "\n",
    "## Saved game name and game ID info\n",
    "with open('app//playful//static//data//all_game_info.txt', 'r') as f:\n",
    "    all_game_info = json.load(f)\n",
    "    \n",
    "gameid_to_name = {}\n",
    "gamename_to_gameid = {}\n",
    "for app in all_game_info:\n",
    "    gameid_to_name[app['appid']] = app['name']\n",
    "    gamename_to_gameid[app['name']] = app['appid']\n",
    "\n",
    "idx_to_name = {}\n",
    "idx_to_gameid = {}\n",
    "name_to_idx = {}\n",
    "gameid_to_idx = {}\n",
    "\n",
    "for idx, gameid in enumerate(unique_games):\n",
    "    idx_to_gameid[idx] = gameid\n",
    "    gameid_to_idx[gameid] = idx\n",
    "    \n",
    "    try:\n",
    "        idx_to_name[idx] = gameid_to_name[gameid]\n",
    "    except KeyError:\n",
    "        idx_to_name[idx] = \"Could not identify this game. Maybe it's new?\"\n",
    "        \n",
    "    try:\n",
    "        name_to_idx[gameid_to_name[gameid]] = idx\n",
    "    except KeyError:\n",
    "        pass\n",
    "      \n",
    "userid_to_idx = {}\n",
    "idx_to_userid = {}\n",
    "for (idx, userid) in enumerate(unique_users):\n",
    "    userid_to_idx[userid] = idx\n",
    "    idx_to_userid[idx] = userid\n",
    "    \n",
    "# examples\n",
    "game_idx = 2000\n",
    "game_id = idx_to_gameid[game_idx]\n",
    "game_name = gameid_to_name[game_id]\n",
    "print(game_name, 'will be game number', game_idx, 'in the interactions matrix and has Steam game ID', game_id)\n",
    "\n",
    "print('\\nThe most-owned games in this sample of data by name instead of game ID:')\n",
    "for gameid in most_popular_game_ids:\n",
    "    print(gameid_to_name[gameid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the sparse interactions matrix\n",
    "I and J specify the locations in the sparse matrix where the data V will go. The data in this case are all 1's that we put in the matrix to indicate which owner owns which game. All of the remaining entries in the matrix are zeroes, meaning we don't have any information about whether a given user is interested in a particular game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_id(idx_to_switch_out, mapper):\n",
    "    return mapper[idx_to_switch_out]\n",
    "\n",
    "I = df.user_id.apply(map_id, args=[userid_to_idx]).values\n",
    "J = df.app_id.apply(map_id, args=[gameid_to_idx]).values \n",
    "V = np.ones_like(I)\n",
    "\n",
    "interaction_matrix = sparse.coo_matrix((V, (I, J)), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets\n",
    "This split is not as straightforward as some other maching learning algorithms because I need *some* information in about what a user owns to make recommendations, so I can't just hold a group of users out entirely. Instead, I split the data into two sets with the same users, but my training data contains 80% of the users' games, and the test data contains the other 20%. The python package LightFM includes a handy function for doing that for me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata, testdata = random_train_test_split(interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement matrix factorization\n",
    "LightFM uses stochastic gradient descent to solve for the latent vectors,or embeddings, that characterize each game and user in the interactions matrix. \n",
    "\n",
    "Hyperparameters that must be chosen for the model include:\n",
    "* the length of the latent vectors (no_components)\n",
    "* the learning rate to use during gradient descent\n",
    "* the number of iterations, or epochs, to use when trying to fit the data\n",
    "* the exact form of the loss function (the default is called WARP)\n",
    "\n",
    "Ideally one would use a grid search or start with random points within a grid search to decide what values to use for the various hyperparameters. That takes awhile, so here I'm showing the fit with the hyperparameters I used. Note that I did not do a proper grid search, but there is graph in backup slides at playful.live showing that the number of components in particular is certainly improved from the default value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x26d4f6175c0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=25, learning_rate=0.045)\n",
    "model.fit(traindata, epochs=40) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall@k\n",
    "There are a lot of different validation metrics one can use to evaluate recommender systems. The one I used when optimizing my hyperparameters is called recall@k.  \n",
    "\n",
    "Recall refers to the number of true positives / (the number of true positives + the number of false negatives), and I like it better than precision (true positives / (true positives + false positives)) here because recall, unike precision, does not assume that a zero in the matrix (lack of ownership) means that person won't like the game if we recommended it. \n",
    "\n",
    "Recall@k tells us this: if I recommend only k games (12 games in this example) out of my list of ~20,000 games to users based on their games in the training data, how likely am I to recommend games that they own that are in my training data? \n",
    "\n",
    "And again LightFM has a handy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047893075195332431"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(model, testdata, k=12).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The item similarity matrix\n",
    "The model item embeddings are vectors that represent each game. (These are the things that the matrix factorization model fitting figured out). We take the dot product of this matrix by its transpose, normalize, and voila, there is a matrix of similarities between games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_similarity_matrix = model.item_embeddings.dot(model.item_embeddings.T)\n",
    "normalizeto = np.array([np.sqrt(np.diagonal(game_similarity_matrix))])\n",
    "game_similarity_matrix = game_similarity_matrix / normalizeto / normalizeto.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cold start problem\n",
    "One major drawback of collaborative filtering is that if a user or game isn't in the interactions matrix, the model has no way to make recommendations. That's why recommenders still need things like game features (developer studio, genre, tags, etc.) and user features (games owned, demographics, etc.). \n",
    "\n",
    "### New games\n",
    "My model never recommends bright, shiny, brand new games. If I retrain the model every week (which I'm not, but one could), then I would start to pick up the new games, but they won't show up right away. If that's the kind of recommendations you want (i.e., of the games that came out in the last, say, month, which ones are most relevant to me as a user?), you are in luck because that is exactly what the Steam store already does, or at least, is trying to do. \n",
    "\n",
    "### New users\n",
    "For a brand new user, I show them the most popular games by number of owners (see list above), but 'new user' in this context doesn't only mean brand new users who don't own any games. It means any user who isn't in the interactions matrix. My app works for any Steam user who owns games, which means I need some information about the user. Specifically, I use the games they own and how many hours they have played each game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API call for user information\n",
    "\n",
    "This example uses my Steam vanityurl (which has to be set by the user in their Steam settings - just having a Steam account name is not enough!), but the app can also use the 17-digit Steam user ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My games\n",
      "[{'appid': 400, 'playtime_forever': 310}, {'appid': 15130, 'playtime_forever': 529}, {'appid': 22330, 'playtime_forever': 4893}, {'appid': 22320, 'playtime_forever': 101}, {'appid': 40700, 'playtime_forever': 551}, {'appid': 3900, 'playtime_forever': 1}, {'appid': 3990, 'playtime_forever': 137}, {'appid': 8800, 'playtime_forever': 30471}, {'appid': 16810, 'playtime_forever': 0}, {'appid': 34440, 'playtime_forever': 0}, {'appid': 34450, 'playtime_forever': 0}, {'appid': 34460, 'playtime_forever': 0}, {'appid': 8930, 'playtime_forever': 39603}, {'appid': 32360, 'playtime_forever': 581}, {'appid': 32460, 'playtime_forever': 675}, {'appid': 61510, 'playtime_forever': 129}, {'appid': 620, 'playtime_forever': 43}, {'appid': 203770, 'playtime_forever': 1473}, {'appid': 39140, 'playtime_forever': 1129}]\n"
     ]
    }
   ],
   "source": [
    "def convert_input_to_userid(input_id):\n",
    "    \"\"\" \n",
    "    Take user input from app (Steam user ID or vanity URL) and output Steam user ID for further API calls ]\n",
    "    \"\"\"\n",
    "    req = Request('http://api.steampowered.com/ISteamUser/ResolveVanityURL/v0001/?key=%s&vanityurl=%s'%(api_key, input_id))\n",
    "\n",
    "    try:\n",
    "        data_raw = urlopen(req).read()\n",
    "    except HTTPError:\n",
    "        return input_id\n",
    "\n",
    "    data_json = json.loads(data_raw)\n",
    "\n",
    "    try:\n",
    "        return int(data_json['response']['steamid'])\n",
    "    except KeyError:\n",
    "        return input_id\n",
    "\n",
    "\n",
    "def get_user_games(user_id):\n",
    "    \"\"\" \n",
    "    Take Steam ID and make an API call to return users's owned games and hours played \n",
    "    \"\"\"\n",
    "    req = Request('http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=%s&steamid=%s&format=json&include_played_free_games=True&include_appinfo=True'%(api_key, user_id))\n",
    "    try:\n",
    "        data_raw = urlopen(req).read()\n",
    "        data_json = json.loads(data_raw)\n",
    "        return data_json['response']['games']\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "example_steam_urlname = 'elizabethferriss' \n",
    "user_id = convert_input_to_userid(example_steam_urlname)\n",
    "user_game_info = get_user_games(user_id)\n",
    "\n",
    "print('My games')\n",
    "print(user_game_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank user's games based on hours played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>hours_played</th>\n",
       "      <th>game_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8930</td>\n",
       "      <td>39603</td>\n",
       "      <td>Sid Meier's Civilization V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8800</td>\n",
       "      <td>30471</td>\n",
       "      <td>Sid Meier's Civilization IV: Beyond the Sword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22330</td>\n",
       "      <td>4893</td>\n",
       "      <td>The Elder Scrolls IV: Oblivion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>203770</td>\n",
       "      <td>1473</td>\n",
       "      <td>Crusader Kings II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39140</td>\n",
       "      <td>1129</td>\n",
       "      <td>FINAL FANTASY VII</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     appid  hours_played                                      game_name\n",
       "12    8930         39603                     Sid Meier's Civilization V\n",
       "7     8800         30471  Sid Meier's Civilization IV: Beyond the Sword\n",
       "2    22330          4893                The Elder Scrolls IV: Oblivion \n",
       "17  203770          1473                              Crusader Kings II\n",
       "18   39140          1129                              FINAL FANTASY VII"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_game_ids = [app['appid'] for app in user_game_info]\n",
    "user_hours_played = [app['playtime_forever'] for app in user_game_info]\n",
    "userdf = pd.DataFrame({'appid': user_game_ids, 'hours_played' : user_hours_played})\n",
    "userdf = userdf.sort_values(by='hours_played', ascending=False)\n",
    "userdf['game_name'] = [gameid_to_name[gameid] for gameid in userdf.appid]\n",
    "user_game_ids = userdf.appid.values\n",
    "user_hours_played = userdf.hours_played.values\n",
    "userdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations based on the user's most-played games\n",
    "For each game, get the column in game similarity matrix for the user's most-played game and sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  People who own Sid Meier's Civilization V also own:\n",
      "Dragon Age: Origins - Ultimate Edition\n",
      "Prison Architect\n",
      "Saints Row IV\n",
      "Stardew Valley\n",
      "The Elder Scrolls V: Skyrim\n",
      "XCOM: Enemy Unknown\n",
      "Saints Row: The Third\n",
      "Left 4 Dead 2\n",
      "\n",
      "  People who own Sid Meier's Civilization IV: Beyond the Sword also own:\n",
      "Arma 2: Operation Arrowhead Beta (Obsolete)\n",
      "F.E.A.R.: Perseus Mandate\n",
      "Valkyria Chronicles™\n",
      "TrackMania Nations Forever\n",
      "Batman: Arkham Asylum GOTY Edition\n",
      "Natural Selection 2\n",
      "Company of Heroes - Legacy Edition\n",
      "The Binding of Isaac\n",
      "\n",
      "  People who own The Elder Scrolls IV: Oblivion  also own:\n",
      "X-COM: Terror from the Deep\n",
      "Space Engineers\n",
      "Magicka\n",
      "Borderlands 2\n",
      "Burnout Paradise: The Ultimate Box\n",
      "Titan Quest\n",
      "Dishonored\n",
      "Orcs Must Die!\n",
      "\n",
      "  People who own Crusader Kings II also own:\n",
      "Medieval II: Total War\n",
      "Mount & Blade: Warband\n",
      "Hearts of Iron IV\n",
      "Democracy 3\n",
      "Rome: Total War\n",
      "Europa Universalis III\n",
      "Stellaris\n",
      "Duke Nukem Forever\n",
      "\n",
      "  People who own FINAL FANTASY VII also own:\n",
      "Path of Exile\n",
      "Orcs Must Die! 2\n",
      "Sanctum 2\n",
      "Dead Island: Epidemic\n",
      "Total War: WARHAMMER\n",
      "FTL: Faster Than Light\n",
      "DARK SOULS™ II\n",
      "Risk of Rain\n",
      "\n",
      "  People who own Monkey Island 2: Special Edition also own:\n",
      "Game of Thrones - A Telltale Games Series\n",
      "Metro 2033 Redux\n",
      "SOMA\n",
      "Oddworld: Abe's Exoddus\n",
      "Sid Meier's Pirates!\n",
      "Dear Esther: Landmark Edition\n",
      "Tropico 4\n",
      "ABZÛ\n",
      "\n",
      "  People who own The Secret of Monkey Island: Special Edition also own:\n",
      "Sam & Max 303: They Stole Max's Brain!\n",
      "Deus Ex: Human Revolution\n",
      "Remember Me\n",
      "Warhammer 40,000: Space Marine\n",
      "System Shock 2\n",
      "Titan Quest: Immortal Throne\n",
      "The Stanley Parable\n",
      "Arma 2: Private Military Company\n",
      "\n",
      "  People who own Machinarium also own:\n",
      "Borderlands\n",
      "Half-Life: Opposing Force\n",
      "Mass Effect 2\n",
      "Duke Nukem 3D: Megaton Edition\n",
      "Half-Life: Source\n",
      "Two Worlds II\n",
      "Deathmatch Classic\n",
      "Team Fortress Classic\n",
      "\n",
      "  People who own Beyond Good & Evil also own:\n",
      "Sniper Elite\n",
      "STAR WARS™: The Force Unleashed™ Ultimate Sith Edition\n",
      "Divinity: Dragon Commander\n",
      "DiRT 3 Complete Edition\n",
      "Besiege\n",
      "Kane & Lynch: Dead Men\n",
      "F1 2016\n",
      "Rising Storm/Red Orchestra 2 Multiplayer\n",
      "\n",
      "  People who own Portal also own:\n",
      "DOOM\n",
      "Half-Life 2: Episode Two\n",
      "Company of Heroes 2\n",
      "Batman: Arkham City GOTY\n",
      "Planetary Annihilation: TITANS\n",
      "The Witcher: Enhanced Edition\n",
      "Half-Life 2: Deathmatch\n",
      "Deus Ex: Human Revolution - Director's Cut\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def idx_to_recs(game_idx):\n",
    "    game_recs_scores = game_similarity_matrix[game_idx]\n",
    "    df = pd.DataFrame({'game_idx':list(idx_to_name.keys()), 'scores':game_recs_scores})\n",
    "    df = df.sort_values(by='scores', ascending=False)\n",
    "    df['gameID'] = [idx_to_gameid[idx] for idx in df.game_idx]\n",
    "    df['games'] = [idx_to_name[idx] for idx in df.game_idx]\n",
    "    df = df[~df.gameID.isin(user_game_ids)] # filter out games already owned\n",
    "    return df['games'].values\n",
    "\n",
    "nrecgroups =  10\n",
    "nrecs_per_group = 8\n",
    "games_already_recommended = []\n",
    "for n in range(nrecgroups):\n",
    "    user_gameid= user_game_ids[n]\n",
    "    print('  People who own', gameid_to_name[user_gameid], 'also own:')\n",
    "    recs = idx_to_recs(gameid_to_idx[user_gameid])\n",
    "    recs = [rec for rec in recs if rec not in games_already_recommended] # don't recommend anything twice\n",
    "    for rec in recs[0:nrecs_per_group]:\n",
    "        games_already_recommended.append(rec)\n",
    "        print(rec)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
