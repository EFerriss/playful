{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playful: Find your new favorite computer game\n",
    "Here is the basic outline of how I  built [an app that recommends computer games on Steam](http://www.playful.live/) using a combination of python and PostgreSQL.\n",
    "\n",
    "## Import stuff\n",
    "My config.py file is not on GitHub. You need your own Steam API key and database information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from app.config import api_key, db_username, db_password, db_host, db_port\n",
    "from urllib.request import Request, urlopen\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pickle\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from scipy import sparse\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape reviews for user IDs\n",
    "Scraping hub has [a detailed example of how to scrape reviews from the Steam store using scrapy]((https://blog.scrapinghub.com/2017/07/07/scraping-the-steam-game-store-with-scrapy/), complete with code in a GitHub repo. \n",
    "\n",
    "I scraped all of the reviews, which took about 4 days, in case later on I want to incorporate some of that information into the recommendations. For now the only thing I'm using from that exercize is a list of ~400,000 unique Steam user IDs of the review writers. I did not include any other Steam users, so my recommendations are biased toward games owned by people who have written reviews. \n",
    "\n",
    "Due to space limitations on GitHub, I am sharing only a small part of 1 of the 3 scrapy output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1094 unique steam user IDs in the sample data.\n"
     ]
    }
   ],
   "source": [
    "def load_reviews():\n",
    "    reviews = []\n",
    "    path_to_scraped_data = 'example_data//'\n",
    "    files = ['scraped_reviews.jl']\n",
    "    \n",
    "    for file in files:\n",
    "        with open(''.join((path_to_scraped_data, file)), 'r') as f:\n",
    "            for line in f:\n",
    "                reviews.append(json.loads(line))\n",
    "                \n",
    "    return reviews\n",
    "\n",
    "scraped_reviews = load_reviews()\n",
    "\n",
    "user_ids = []\n",
    "for review in scraped_reviews:\n",
    "    try:\n",
    "        user_ids.append(review['user_id'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "unique_users = list(set(user_ids))\n",
    "print('There are', len(unique_users), 'unique steam user IDs in the sample data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API calls for game ownership\n",
    "This took about 5 minutes, and you have to be online for the API call to work.\n",
    "\n",
    "In the real app, I'm using a pickled version of the results to avoid complications in case a user deletes their account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGamesOwned(player_id):\n",
    "    req = Request('http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=%s&steamid=%s&format=json&include_played_free_games=True&include_appinfo=True'%(api_key, player_id))\n",
    "    try:\n",
    "        data_raw = urlopen(req).read()\n",
    "        data_json = json.loads(data_raw)\n",
    "        return data_json['response']['games']\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def get_all_games_owned_by_players(user_ids):\n",
    "    users_and_their_games = {}\n",
    "    for idx, gamer_id in enumerate(user_ids):\n",
    "        users_and_their_games[gamer_id] = getGamesOwned(gamer_id)\n",
    "    return users_and_their_games\n",
    "\n",
    "users_and_their_games = get_all_games_owned_by_players(unique_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the ownership data into pandas and PostgreSQL\n",
    "Every user-game pair gets its own row in the database. For example, say I have data for only 2 unique Steam users, Katie and Minchun. If Katie owns 20 games and Minchun owns 3 games, I'll end up with 23 rows. \n",
    "\n",
    "You have to have a SQL server installed and running with apppropriate password information for this section to work. Also, I used Windows. The syntax will be different on a Mac or Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211500</td>\n",
       "      <td>76561198382802605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>427100</td>\n",
       "      <td>76561198382802605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324310</td>\n",
       "      <td>76561198382802605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12520</td>\n",
       "      <td>76561198172905937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11480</td>\n",
       "      <td>76561198172905937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id            user_id\n",
       "0  211500  76561198382802605\n",
       "1  427100  76561198382802605\n",
       "2  324310  76561198382802605\n",
       "3   12520  76561198172905937\n",
       "4   11480  76561198172905937"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_column = []\n",
    "app_column = []\n",
    "\n",
    "for user in unique_users:\n",
    "    for game in users_and_their_games[user]:\n",
    "        user_column.append(user)\n",
    "        app_column.append(game['appid'])\n",
    "\n",
    "user_game_df = pd.DataFrame({'user_id':user_column, 'app_id':app_column})\n",
    "\n",
    "db_name  = 'playful'\n",
    "engine = create_engine('postgresql+psycopg2://%s:%s@%s:%s/%s'%(db_username,db_password,db_host,db_port,db_name))\n",
    "\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "    \n",
    "user_game_df.to_sql('user_games_table', engine, if_exists='replace')\n",
    "\n",
    "user_game_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL query for most popular games\n",
    "This is how I came up with the list of the 12 most popular games on the app homepage. I'll convert the game IDs into actual names shortly.\n",
    "\n",
    "At scale, this SQL query was much faster than a similar analysis in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the IDs of the most-owned games\n",
      "223530\n",
      "550\n",
      "72850\n",
      "218620\n",
      "730\n",
      "620\n",
      "230410\n",
      "205790\n",
      "304930\n",
      "4000\n",
      "238960\n",
      "49520\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\" SELECT app_id, COUNT(user_id) AS \"n_owners\"\n",
    "                FROM user_games_table\n",
    "                GROUP BY app_id\n",
    "                ORDER BY n_owners DESC\n",
    "                LIMIT 12\n",
    "            \"\"\"\n",
    "\n",
    "con = None\n",
    "con = psycopg2.connect(database=db_name, user=db_username, password=db_password, host=db_host, port=db_port)\n",
    "most_popular_game_ids = pd.read_sql_query(sql_query, con).app_id.values\n",
    "\n",
    "print('Here are the IDs of the most-owned games')\n",
    "for game in most_popular_game_ids:\n",
    "    print(game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine unique users and games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points 234568\n",
      "number of users: 911\n",
      "number of games: 19946\n",
      "Sparsity of data in the example interactions matrix: 1.291%\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\" SELECT *\n",
    "                FROM user_games_table\n",
    "            \"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sql_query, con)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "unique_users = df.user_id.unique()\n",
    "unique_games = df.app_id.unique()\n",
    "\n",
    "n_users = len(unique_users)\n",
    "n_games = len(unique_games)\n",
    "n_datapoints = len(df)\n",
    "sparsity = 100* n_datapoints / (n_users*n_games)\n",
    "\n",
    "print('number of data points', n_datapoints)\n",
    "print('number of users:', n_users)\n",
    "print('number of games:', n_games)\n",
    "print('Sparsity of data in the example interactions matrix: {:4.3f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappers\n",
    "Each game has 3 different ways we can refer to it:\n",
    "* the game's name (gamename)\n",
    "* the game's Steam ID (gameid)\n",
    "* the game's location in the interactions matrix (idx)\n",
    "\n",
    "I made 6 different mapper dictionaries to convert from one game representation of a game to another. The game name to Steam ID mapping is from the API, but here and in the app I'm using stored data for that data and 2 of the mapper dictionaries. \n",
    "\n",
    "The users also get mapped to indexes in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Killing Floor: Incursion will be game number 2000 in the interactions matrix and has Steam game ID 690810\n",
      "\n",
      "The most-owned games in this sample of data by name instead of game ID:\n",
      "Left 4 Dead 2 Beta\n",
      "Left 4 Dead 2\n",
      "The Elder Scrolls V: Skyrim\n",
      "PAYDAY 2\n",
      "Counter-Strike: Global Offensive\n",
      "Portal 2\n",
      "Warframe\n",
      "Dota 2 Test\n",
      "Unturned\n",
      "Garry's Mod\n",
      "Path of Exile\n",
      "Borderlands 2\n"
     ]
    }
   ],
   "source": [
    "## Game name and game ID information from API\n",
    "# req = Request('http://api.steampowered.com/ISteamApps/GetAppList/v2/?key=%s'%(api_key))\n",
    "# data_raw = urlopen(req).read()\n",
    "# data_json = json.loads(data_raw)['applist']['apps']\n",
    "\n",
    "## Saved game name and game ID info\n",
    "with open('app//playful//static//data//all_game_info.txt', 'r') as f:\n",
    "    all_game_info = json.load(f)\n",
    "    \n",
    "gameid_to_name = {}\n",
    "gamename_to_gameid = {}\n",
    "for app in all_game_info:\n",
    "    gameid_to_name[app['appid']] = app['name']\n",
    "    gamename_to_gameid[app['name']] = app['appid']\n",
    "\n",
    "idx_to_name = {}\n",
    "idx_to_gameid = {}\n",
    "name_to_idx = {}\n",
    "gameid_to_idx = {}\n",
    "\n",
    "for idx, gameid in enumerate(unique_games):\n",
    "    idx_to_gameid[idx] = gameid\n",
    "    gameid_to_idx[gameid] = idx\n",
    "    \n",
    "    try:\n",
    "        idx_to_name[idx] = gameid_to_name[gameid]\n",
    "    except KeyError:\n",
    "        idx_to_name[idx] = \"Could not identify this game. Maybe it's new?\"\n",
    "        \n",
    "    try:\n",
    "        name_to_idx[gameid_to_name[gameid]] = idx\n",
    "    except KeyError:\n",
    "        pass\n",
    "      \n",
    "userid_to_idx = {}\n",
    "idx_to_userid = {}\n",
    "for (idx, userid) in enumerate(unique_users):\n",
    "    userid_to_idx[userid] = idx\n",
    "    idx_to_userid[idx] = userid\n",
    "    \n",
    "# examples\n",
    "game_idx = 2000\n",
    "game_id = idx_to_gameid[game_idx]\n",
    "game_name = gameid_to_name[game_id]\n",
    "print(game_name, 'will be game number', game_idx, 'in the interactions matrix and has Steam game ID', game_id)\n",
    "\n",
    "print('\\nThe most-owned games in this sample of data by name instead of game ID:')\n",
    "for gameid in most_popular_game_ids:\n",
    "    print(gameid_to_name[gameid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the sparse interactions matrix\n",
    "I and J specify the locations in the sparse matrix where the data V will go.\n",
    "\n",
    "### Ownership data\n",
    "The data in this case are all 1's that we put in the matrix to indicate which owner owns which game. All of the remaining entries in the matrix are zeroes, meaning we don't have any information about whether a given user is interested in a particular game.\n",
    "\n",
    "### Hours played data\n",
    "The API calls also give me the number of hours each user has played, so I could use some function of that number instead of just the binary owns/doesn't own. I played around with this a little bit, and LightFM can do that, but it's not as simple as just swapping the ones in the data for the hours played. They need to go in as sample weights instead, and in a sparse matrix form that matches the training data. If only I had another two weeks...\n",
    "\n",
    "Here are some additional considerations if I were to use hours played data. \n",
    "* **What does it mean when a user owns a game but hasn't played it?**   \n",
    "Maybe they just bought the game and are really super excited about it, but I would assume that means they weren't that interested in the game, and so ideally I would put a -1 in the matrix. I don't think LightFM can handle that.\n",
    "* **Sometimes people leave a game on even when they aren't playing it.**    \n",
    "I could either apply a time cutoff or use the log of the hours played.\n",
    "* **Some games end quickly while others lend themselves to much longer playtimes.**   \n",
    "I could normalize the times by average time played or perhaps based on genre.\n",
    "* **Older games have an advantage.**  \n",
    "This is true, and my model also totally fails to account for changes in user preferences over time. However! The API call also tells me how long a user has spent playing each game in the last two weeks, so I could train on just that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_id(idx_to_switch_out, mapper):\n",
    "    return mapper[idx_to_switch_out]\n",
    "\n",
    "I = df.user_id.apply(map_id, args=[userid_to_idx]).values\n",
    "J = df.app_id.apply(map_id, args=[gameid_to_idx]).values \n",
    "V = np.ones_like(I)\n",
    "\n",
    "interaction_matrix = sparse.coo_matrix((V, (I, J)), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets\n",
    "This split is not as straightforward as some other maching learning algorithms because I need *some* information in about what a user owns to make recommendations, so I can't just hold a group of users out entirely. Instead, I split the data into two sets with the same users, but my training data contains 80% of the users' games, and the test data contains the other 20%. The python package LightFM includes a handy function for doing that for me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata, testdata = random_train_test_split(interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement matrix factorization\n",
    "LightFM uses stochastic gradient descent to solve for the latent vectors,or embeddings, that characterize each game and user in the interactions matrix. \n",
    "\n",
    "Hyperparameters that must be chosen for the model include:\n",
    "* the length of the latent vectors (no_components)\n",
    "* the learning rate to use during gradient descent\n",
    "* the number of iterations, or epochs, to use when trying to fit the data\n",
    "* the exact form of the loss function (the default is called WARP)\n",
    "\n",
    "Ideally one would use a grid search or start with random points within a grid search to decide what values to use for the various hyperparameters. That takes awhile, so here I'm showing the fit with the hyperparameters I used. Note that I did not do a proper grid search, but there is graph in backup slides at playful.live showing that the number of components in particular is certainly improved from the default value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1990fc197b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=25, learning_rate=0.045)\n",
    "model.fit(traindata, epochs=40) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall@k\n",
    "There are a lot of different validation metrics one can use to evaluate recommender systems. The one I used when optimizing my hyperparameters is called recall@k.  \n",
    "\n",
    "Recall refers to the number of true positives / (the number of true positives + the number of false negatives), and I like it better than precision (true positives / (true positives + false positives)) here because recall, unike precision, does not assume that a zero in the matrix (lack of ownership) means that person won't like the game if we recommended it. \n",
    "\n",
    "Recall@k tells us this: if I recommend only k games (12 games in this example) out of my list of ~20,000 games to users based on their games in the training data, how likely am I to recommend the games they own that I held out when training the model? \n",
    "\n",
    "And again LightFM has a handy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@12 for this example: 0.0476204036598\n",
      "recall@12 for my actual model: 0.083\n"
     ]
    }
   ],
   "source": [
    "example_recall = recall_at_k(model, testdata, k=12).mean()\n",
    "true_model_recall = 0.083\n",
    "\n",
    "print('recall@12 for this example:', example_recall)\n",
    "print('recall@12 for my actual model:', true_model_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with just recommending the most popular games\n",
    "This is a super relevant and important comparison to make, but the math is not straightforward. I tried simulating it with a for loop, but that approach hadn't found a single hit (a randomly dropped game that was one of the 12 most popular games) even after running all night. In contrast, LightFM's recall_at_k function is incredibly fast, I think because they're making good use of things like cython and sparse matrices. If I had another two weeks, this comparison is definitely something I would want to sort out. Just qualitatively though, I will note that the there is a lot of diversity in the genres of those 12 most-owned games (e.g., a physics sandbox vs a first-person shooter vs a strategy game), and the recommendations my model produces have a lot more game features that are obviously in common with each other.\n",
    "\n",
    "###  Comparison with random guessing\n",
    "If we randomly pick 12 games out of 20K and don't care about the order within that list of 12, the probability of picking the 12 games that we dropped is related to the [hypergeometric distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution) and works out 12 / 20K. Note the exact number of unique games in the Steam store changed between when I first created my model and when I created this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of picking the 12 dropped games by random guessing: 0.0006016243858417727\n",
      "which is 138 times worse than my model\n"
     ]
    }
   ],
   "source": [
    "print('Chance of picking the 12 dropped games by random guessing:', 12./len(unique_games))\n",
    "print('which is', round(true_model_recall/(12./len(unique_games))), 'times worse than my model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The item similarity matrix\n",
    "The model item embeddings are vectors that represent each game. (These are the things that the matrix factorization model fitting figured out). We take the dot product of this matrix by its transpose, normalize, and voila, there is a matrix of similarities between games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_similarity_matrix = model.item_embeddings.dot(model.item_embeddings.T)\n",
    "normalizeto = np.array([np.sqrt(np.diagonal(game_similarity_matrix))])\n",
    "game_similarity_matrix = game_similarity_matrix / normalizeto / normalizeto.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cold start problem\n",
    "One major drawback of collaborative filtering is that if a user or game isn't in the interactions matrix, the model has no way to make recommendations. That's why recommenders still need things like game features (developer studio, genre, tags, etc.) and user features (games owned, demographics, etc.). \n",
    "\n",
    "### New games\n",
    "My model never recommends any bright, shiny, brand new games. If I were to retrain the model every week (which I would definitely set up if I had another 2 weeks to work on this), then I would start to pick up the new games, but they won't show up right away. If that's the kind of recommendations you want (i.e., of the games that came out in the last, say, month, which ones are most relevant to me as a user?), you are in luck because that is exactly what the Steam store already does, or at least, is trying to do. \n",
    "\n",
    "### New users\n",
    "For a brand new user, I show them the most popular games by number of owners (see list above), but 'new user' in this context doesn't only mean brand new users who don't own any games. It means any user who isn't in the interactions matrix. My app works for any Steam user who owns games, which means I need some information about the user. Specifically, I use the games they own and how many hours they have played each game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API call for user information\n",
    "\n",
    "This example uses my Steam vanityurl (which has to be set by the user in their Steam settings - just having a Steam account name is not enough!), but the app can also use the 17-digit Steam user ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My games\n",
      "[{'appid': 400, 'playtime_forever': 310}, {'appid': 15130, 'playtime_forever': 529}, {'appid': 22330, 'playtime_forever': 4893}, {'appid': 22320, 'playtime_forever': 101}, {'appid': 40700, 'playtime_forever': 551}, {'appid': 3900, 'playtime_forever': 1}, {'appid': 3990, 'playtime_forever': 137}, {'appid': 8800, 'playtime_forever': 30471}, {'appid': 16810, 'playtime_forever': 0}, {'appid': 34440, 'playtime_forever': 0}, {'appid': 34450, 'playtime_forever': 0}, {'appid': 34460, 'playtime_forever': 0}, {'appid': 8930, 'playtime_forever': 39603}, {'appid': 32360, 'playtime_forever': 581}, {'appid': 32460, 'playtime_forever': 675}, {'appid': 61510, 'playtime_forever': 129}, {'appid': 620, 'playtime_forever': 43}, {'appid': 203770, 'playtime_forever': 1473}, {'appid': 39140, 'playtime_forever': 1129}]\n"
     ]
    }
   ],
   "source": [
    "def convert_input_to_userid(input_id):\n",
    "    \"\"\" \n",
    "    Take user input from app (Steam user ID or vanity URL) and output Steam user ID for further API calls ]\n",
    "    \"\"\"\n",
    "    req = Request('http://api.steampowered.com/ISteamUser/ResolveVanityURL/v0001/?key=%s&vanityurl=%s'%(api_key, input_id))\n",
    "\n",
    "    try:\n",
    "        data_raw = urlopen(req).read()\n",
    "    except HTTPError:\n",
    "        return input_id\n",
    "\n",
    "    data_json = json.loads(data_raw)\n",
    "\n",
    "    try:\n",
    "        return int(data_json['response']['steamid'])\n",
    "    except KeyError:\n",
    "        return input_id\n",
    "\n",
    "\n",
    "def get_user_games(user_id):\n",
    "    \"\"\" \n",
    "    Take Steam ID and make an API call to return users's owned games and hours played \n",
    "    \"\"\"\n",
    "    req = Request('http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=%s&steamid=%s&format=json&include_played_free_games=True&include_appinfo=True'%(api_key, user_id))\n",
    "    try:\n",
    "        data_raw = urlopen(req).read()\n",
    "        data_json = json.loads(data_raw)\n",
    "        return data_json['response']['games']\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "example_steam_urlname = 'elizabethferriss' \n",
    "user_id = convert_input_to_userid(example_steam_urlname)\n",
    "user_game_info = get_user_games(user_id)\n",
    "\n",
    "print('My games')\n",
    "print(user_game_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank user's games based on hours played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>hours_played</th>\n",
       "      <th>game_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8930</td>\n",
       "      <td>39603</td>\n",
       "      <td>Sid Meier's Civilization V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8800</td>\n",
       "      <td>30471</td>\n",
       "      <td>Sid Meier's Civilization IV: Beyond the Sword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22330</td>\n",
       "      <td>4893</td>\n",
       "      <td>The Elder Scrolls IV: Oblivion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>203770</td>\n",
       "      <td>1473</td>\n",
       "      <td>Crusader Kings II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39140</td>\n",
       "      <td>1129</td>\n",
       "      <td>FINAL FANTASY VII</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     appid  hours_played                                      game_name\n",
       "12    8930         39603                     Sid Meier's Civilization V\n",
       "7     8800         30471  Sid Meier's Civilization IV: Beyond the Sword\n",
       "2    22330          4893                The Elder Scrolls IV: Oblivion \n",
       "17  203770          1473                              Crusader Kings II\n",
       "18   39140          1129                              FINAL FANTASY VII"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_game_ids = [app['appid'] for app in user_game_info]\n",
    "user_hours_played = [app['playtime_forever'] for app in user_game_info]\n",
    "userdf = pd.DataFrame({'appid': user_game_ids, 'hours_played' : user_hours_played})\n",
    "userdf = userdf.sort_values(by='hours_played', ascending=False)\n",
    "userdf['game_name'] = [gameid_to_name[gameid] for gameid in userdf.appid]\n",
    "user_game_ids = userdf.appid.values\n",
    "user_hours_played = userdf.hours_played.values\n",
    "userdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations based on the user's most-played games\n",
    "For each game, get the column in game similarity matrix for the user's most-played game and sort.\n",
    "\n",
    "The recommendations here are much different from the ones on the actual app because here I'm only using a very small selection of users to train my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  People who own Sid Meier's Civilization V also own:\n",
      "Warhammer 40,000: Dawn of War II - Retribution\n",
      "Call of Duty: Black Ops\n",
      "Star Conflict\n",
      "Fallout Shelter\n",
      "Magicka\n",
      "Call of Duty: Black Ops - Multiplayer\n",
      "Torchlight\n",
      "This War of Mine\n",
      "\n",
      "  People who own Sid Meier's Civilization IV: Beyond the Sword also own:\n",
      "Saints Row 2\n",
      "STAR WARS™: Knights of the Old Republic™\n",
      "Pillars of Eternity\n",
      "Torchlight II\n",
      "Divinity: Original Sin (Classic)\n",
      "Titan Quest Anniversary Edition\n",
      "Rogue Legacy\n",
      "Darksiders\n",
      "\n",
      "  People who own The Elder Scrolls IV: Oblivion  also own:\n",
      "Need for Speed: Hot Pursuit\n",
      "Brütal Legend\n",
      "Amnesia: The Dark Descent\n",
      "Grand Theft Auto: Vice City\n",
      "The Elder Scrolls V: Skyrim\n",
      "Arma 2: DayZ Mod\n",
      "Hotline Miami\n",
      "Metro 2033\n",
      "\n",
      "  People who own Crusader Kings II also own:\n",
      "Worms Reloaded\n",
      "The Witcher 3: Wild Hunt\n",
      "Company of Heroes: Opposing Fronts\n",
      "Rising Storm/Red Orchestra 2 Multiplayer\n",
      "RimWorld\n",
      "Castle Crashers\n",
      "Don't Starve Together\n",
      "Natural Selection 2\n",
      "\n",
      "  People who own FINAL FANTASY VII also own:\n",
      "STAR WARS™ Empire at War: Gold Pack\n",
      "The Elder Scrolls V: Skyrim Special Edition\n",
      "Tomb Raider: Legend\n",
      "F.E.A.R. 3\n",
      "Deus Ex: Game of the Year Edition\n",
      "STAR WARS™ Jedi Knight II: Jedi Outcast™\n",
      "Middle-earth™: Shadow of Mordor™\n",
      "Enclave\n",
      "\n",
      "  People who own Monkey Island 2: Special Edition also own:\n",
      "Rome: Total War - Alexander\n",
      "Spelunky\n",
      "BioShock Remastered\n",
      "Max Payne 3\n",
      "Far Cry\n",
      "The Wolf Among Us\n",
      "Half-Life 2: Deathmatch\n",
      "Grand Theft Auto: San Andreas\n",
      "\n",
      "  People who own The Secret of Monkey Island: Special Edition also own:\n",
      "Valkyria Chronicles™\n",
      "SEGA Mega Drive & Genesis Classics\n",
      "F.E.A.R.: Perseus Mandate\n",
      "Shadowrun Returns\n",
      "Deus Ex: Human Revolution - Director's Cut\n",
      "BioShock 2 Remastered\n",
      "The Ultimate DOOM\n",
      "Batman™: Arkham Origins\n",
      "\n",
      "  People who own Machinarium also own:\n",
      "Hollow Knight\n",
      "Moonbase Alpha\n",
      "Spore: Galactic Adventures\n",
      "X3: Reunion\n",
      "Unreal Tournament 3: Black Edition\n",
      "Dead Rising 2\n",
      "Call of Duty: Black Ops III\n",
      "F.E.A.R.\n",
      "\n",
      "  People who own Beyond Good & Evil also own:\n",
      "Gothic II: Gold Edition\n",
      "Creeper World 3: Arc Eternal\n",
      "Quantum Break\n",
      "Gothic 3\n",
      "Back to the Future: Ep 1 - It's About Time\n",
      "Dragon Nest\n",
      "Leisure Suit Larry in the Land of the Lounge Lizards: Reloaded\n",
      "Viking: Battle for Asgard\n",
      "\n",
      "  People who own Portal also own:\n",
      "Half-Life 2: Lost Coast\n",
      "PAYDAY 2\n",
      "Cities: Skylines\n",
      "Half-Life\n",
      "Half-Life 2\n",
      "Elite Dangerous\n",
      "BioShock Infinite\n",
      "Kerbal Space Program\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def idx_to_recs(game_idx):\n",
    "    game_recs_scores = game_similarity_matrix[game_idx]\n",
    "    df = pd.DataFrame({'game_idx':list(idx_to_name.keys()), 'scores':game_recs_scores})\n",
    "    df = df.sort_values(by='scores', ascending=False)\n",
    "    df['gameID'] = [idx_to_gameid[idx] for idx in df.game_idx]\n",
    "    df['games'] = [idx_to_name[idx] for idx in df.game_idx]\n",
    "    df = df[~df.gameID.isin(user_game_ids)] # filter out games already owned\n",
    "    return df['games'].values\n",
    "\n",
    "nrecgroups =  10\n",
    "nrecs_per_group = 8\n",
    "games_already_recommended = []\n",
    "for n in range(nrecgroups):\n",
    "    user_gameid= user_game_ids[n]\n",
    "    print('  People who own', gameid_to_name[user_gameid], 'also own:')\n",
    "    recs = idx_to_recs(gameid_to_idx[user_gameid])\n",
    "    recs = [rec for rec in recs if rec not in games_already_recommended] # don't recommend anything twice\n",
    "    for rec in recs[0:nrecs_per_group]:\n",
    "        games_already_recommended.append(rec)\n",
    "        print(rec)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
